{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAM Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Published_ -> The database was first published in at the ICDAR 1999.  \n",
    "\n",
    "\n",
    "About dataset\n",
    "------------------\n",
    "The database contains forms of unconstrained handwritten text, which were scanned at a resolution of 300dpi and saved as PNG images with 256 gray levels. \n",
    "\n",
    "The IAM Handwriting Database 3.0 is structured as follows:\n",
    "- 657 writers contributed samples of their handwriting\n",
    "- 1,539 pages of scanned text\n",
    "- 5,685 isolated and labeled sentences\n",
    "- 13,353 isolated and labeled text lines\n",
    "- 115,320 isolated and labeled words\n",
    "\n",
    "The words have been extracted from pages of scanned text using an automatic segmentation scheme and were verified manually. \n",
    "- Paper name - Automatic Segmentation of the IAM Off-line Database for Handwritten English Text\n",
    "- Authors Matthias Zimmermann, Horst Bunke\n",
    "- Link - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.652.1885&rep=rep1&type=pdf\n",
    "\n",
    "\n",
    "File format\n",
    "======\n",
    "\n",
    "- __form.txt__\n",
    "  - format: a01-000u 000 2 prt 7 5 52 36\n",
    "  - a01-000u  -> form id\n",
    "  - 000       -> writer id\n",
    "  - 2         -> number of sentences\n",
    "  - prt       -> word segmentation\n",
    "    - prt: some lines correctly segmented\n",
    "    - all: all lines correctly segmented\n",
    "  - 7 5       -> 5 of 7 lines are correctly segmented into words\n",
    "  - 52 36     -> the form contains 52 words, 36 are in lines which have been correctly segmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T05:04:53.266753Z",
     "start_time": "2020-01-20T05:04:47.482949Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from itertools import islice\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a dictionary from forms.txt. To store writer and their forms information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T05:16:43.326765Z",
     "start_time": "2020-01-20T05:16:43.314288Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to store each writer and its form\n",
    "writer_form = defaultdict(list)\n",
    "forms_file_path = \"D:\\\\dataset\\\\IAM\\\\forms.txt\"\n",
    "with open(forms_file_path) as f:\n",
    "    for line in islice(f, 16, None):\n",
    "        line_list = line.split(' ')\n",
    "        form_id = line_list[0]\n",
    "        writer = line_list[1]\n",
    "        writer_form[writer].append(form_id)\n",
    "list(writer_form.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T05:05:00.052241Z",
     "start_time": "2020-01-20T05:05:00.023794Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#print writer and its no of forms\n",
    "print(\"Writer id \\t No. of form\")\n",
    "no_of_form_no_of_writer = defaultdict(int)\n",
    "for key, value in sorted(writer_form.items(), key= lambda kv : len(kv[1]),reverse= True):\n",
    "    print(f\"{key}\\t\\t\\t{len(value)}\")\n",
    "    no_of_form_no_of_writer[len(value)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T05:05:04.867810Z",
     "start_time": "2020-01-20T05:05:04.863319Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#no_of_form - no_of_writer\n",
    "print(\"No. of form \\t No. of Writer\")\n",
    "for key, value in sorted(no_of_form_no_of_writer.items()):\n",
    "    print(f\"{key}\\t\\t\\t{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe here, more than half of the number of writers have written only 1 form. The distribution of number of form per writer is unequal. So this could be a challenge because most of the writers have not written many forms, so we have less data to train our model for such writers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset available in forms, sentences, lines, words format. For all type of data the form_id and writer_id is same.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T05:37:59.621812Z",
     "start_time": "2020-01-20T05:37:59.607339Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Extract all word image of a writer to destination folder\n",
    "def getWriterWordData( writer_id, writer_form_dict, source_path, dest_path):\n",
    "    '''Extract all image written by author to a folder.'''\n",
    "    if(not os.path.exists(dest_path)):\n",
    "            os.mkdir(dest_path)\n",
    "    writer_id = str(writer_id)\n",
    "    \n",
    "    if(len(writer_form_dict[writer_id]) == 0):\n",
    "        print(\"Invalid Writer id\")\n",
    "        return False\n",
    "    else:\n",
    "        dest_fol_path = os.path.join(dest_path,writer_id)\n",
    "        \n",
    "        if(not os.path.exists(dest_fol_path)):\n",
    "            os.mkdir(dest_fol_path)\n",
    "            \n",
    "        fol_list = writer_form_dict[writer_id]\n",
    "        for fol in fol_list:\n",
    "            fol_name_split = fol.split(\"-\")\n",
    "            parent_fol = fol_name_split[0]\n",
    "            parent_fol_path = os.path.join(source_path,parent_fol)\n",
    "            fol_path = os.path.join(parent_fol_path,fol)\n",
    "            files = os.listdir(fol_path)\n",
    "            for f in files:\n",
    "                shutil.copy(fol_path+'\\\\'+f, dest_fol_path+'\\\\'+f)\n",
    "        print(\"Extracted successfully writer \",writer_id)\n",
    "        return True\n",
    "    \n",
    "#Extract all form image of a writer to destination folder\n",
    "def getWriterFormData( writer_id, writer_form_dict, source_path, dest_path):\n",
    "    '''Extract all image written by author to a folder.'''\n",
    "    if(not os.path.exists(dest_path)):\n",
    "            os.mkdir(dest_path)\n",
    "    writer_id = str(writer_id)\n",
    "    \n",
    "    if(len(writer_form_dict[writer_id]) == 0):\n",
    "        print(\"Invalid Writer id\")\n",
    "        return False\n",
    "    else:\n",
    "        dest_fol_path = os.path.join(dest_path,writer_id)\n",
    "        \n",
    "        if(not os.path.exists(dest_fol_path)):\n",
    "            os.mkdir(dest_fol_path)\n",
    "            \n",
    "        form_list = writer_form_dict[writer_id]\n",
    "        for form in form_list:\n",
    "            form_img = form + \".png\"\n",
    "            form_img_path = os.path.join(source_path,form_img)\n",
    "            shutil.copy(form_img_path, dest_fol_path + \"\\\\\" +form_img )\n",
    "        print(\"Extracted successfully writer \",writer_id)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T05:39:58.678061Z",
     "start_time": "2020-01-20T05:39:47.415187Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# extracting data \n",
    "sourcepath = 'D:\\\\dataset\\\\IAM\\\\forms'\n",
    "destpath = 'D:\\\\dataset\\\\exp\\\\forms_10'\n",
    "wid_list = [150,151,152,153,154,384,551,552,588,635,670,671]\n",
    "for wid in wid_list:\n",
    "    getWriterFormData(wid, writer_form, sourcepath, destpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression\n",
    "__The images in dataset are of unequal heights. So we compress the image and change the height of the image to a fixed pixel. The width of image is changed accordingly so that the aspect ratio of the image doesn't change.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T13:20:26.172545Z",
     "start_time": "2020-01-07T13:20:26.164550Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compress func\n",
    "import os\n",
    "from PIL import Image \n",
    "\n",
    "def compress(img_path, new_height, comp_img_path):\n",
    "    '''\n",
    "    Input : img_path, new_height, comp_img_path\n",
    "    Output : new file path\n",
    "    '''\n",
    "    if not os.path.exists(comp_img_path):\n",
    "        os.makedirs(comp_img_path)\n",
    "    fname = img_path.split(\"\\\\\")[-1]\n",
    "    img = Image.open(img_path)\n",
    "    hpercent = (new_height / float(img.size[1]))\n",
    "    wsize = int((float(img.size[0]) * float(hpercent)))\n",
    "    img = img.resize((wsize, new_height), Image.ANTIALIAS)\n",
    "    img.save(os.path.join(comp_img_path, fname))\n",
    "    return os.path.join(comp_img_path, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T13:20:54.896473Z",
     "start_time": "2020-01-07T13:20:54.892476Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compressing images\n",
    "# paths = glob.glob(\"D:\\\\dataset\\\\exp\\\\all\\\\*\\\\*.png\")\n",
    "# for path in paths:\n",
    "#     l = path.split(\"\\\\\")\n",
    "#     new_path = \"D:\\\\dataset\\\\exp\\\\all_comp_128\\\\\" + l[4]\n",
    "#     compress(path,128,new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing unwanted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T13:21:14.279757Z",
     "start_time": "2020-01-07T13:21:14.275759Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Binarization function\n",
    "def binarize(x):\n",
    "    if(x > 200):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "vect_binarize = np.vectorize(binarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-07T13:32:01.437Z"
    }
   },
   "outputs": [],
   "source": [
    "# removing unwanted data\n",
    "del_files_path_list = list()\n",
    "count = 0\n",
    "for path in glob.glob(\"D:\\\\dataset\\\\exp\\\\all_comp_128\\\\*\\\\*.png\"):\n",
    "    im = Image.open(path)\n",
    "    im_np = np.array(im)\n",
    "    im_np = vect_binarize(im_np)\n",
    "    ratio = np.sum(im_np)/np.size(im_np)\n",
    "    if(ratio < 0.6):\n",
    "        shutil.copy(path,\"D:\\\\dataset\\\\exp\\\\temp\")\n",
    "#         os.remove(path)\n",
    "        del_files_path_list.append(path)\n",
    "        count+=1\n",
    "        print(count,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unwanted data\n",
    "delete_it_list = list()\n",
    "for path in glob.glob(\"D:\\\\dataset\\\\exp\\\\temp\\\\*.png\"):\n",
    "    delete_it_list.append(path.split(\"\\\\\")[4])\n",
    "\n",
    "count = 0\n",
    "for path in glob.glob(\"D:\\\\dataset\\\\exp\\\\all_comp_128\\\\*\\\\*.png\"):\n",
    "    fname = path.split(\"\\\\\")[5]\n",
    "    if(fname in delete_it_list):\n",
    "        shutil.copy(path,\"D:\\\\dataset\\\\exp\\\\temp2\")\n",
    "        os.remove(path)\n",
    "        count+=1\n",
    "        print(count,end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
